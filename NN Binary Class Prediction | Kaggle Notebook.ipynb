{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib                # For plotting and visualization\nimport matplotlib.pyplot as plt  \nfrom pandas.plotting import parallel_coordinates\nimport seaborn as sns            # For statistical data visualization\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:12:49.243810Z","iopub.execute_input":"2024-08-29T14:12:49.244215Z","iopub.status.idle":"2024-08-29T14:12:51.009972Z","shell.execute_reply.started":"2024-08-29T14:12:49.244176Z","shell.execute_reply":"2024-08-29T14:12:51.008900Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For machine learning\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, roc_auc_score, median_absolute_error, matthews_corrcoef,\n                             f1_score, confusion_matrix, classification_report)\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n\nfrom tensorflow.keras.models import Sequential,load_model\nfrom tensorflow.keras.layers import Dense,Dropout,Input,BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:12:51.012143Z","iopub.execute_input":"2024-08-29T14:12:51.012764Z","iopub.status.idle":"2024-08-29T14:13:06.713701Z","shell.execute_reply.started":"2024-08-29T14:12:51.012706Z","shell.execute_reply":"2024-08-29T14:13:06.712474Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:13:06.715894Z","iopub.execute_input":"2024-08-29T14:13:06.716586Z","iopub.status.idle":"2024-08-29T14:13:17.404817Z","shell.execute_reply.started":"2024-08-29T14:13:06.716543Z","shell.execute_reply":"2024-08-29T14:13:17.403733Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv')\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:13:17.406016Z","iopub.execute_input":"2024-08-29T14:13:17.406350Z","iopub.status.idle":"2024-08-29T14:13:23.555013Z","shell.execute_reply.started":"2024-08-29T14:13:17.406315Z","shell.execute_reply":"2024-08-29T14:13:23.553916Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"for column in df_train.columns:\n    mode = df_train[column].mode()[0]\n    df_train[column].fillna(mode, inplace=True)\n\nfor column in df_test.columns:\n    mode = df_test[column].mode()[0]\n    df_test[column].fillna(mode, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:13:58.192858Z","iopub.execute_input":"2024-08-29T14:13:58.193830Z","iopub.status.idle":"2024-08-29T14:14:08.155647Z","shell.execute_reply.started":"2024-08-29T14:13:58.193780Z","shell.execute_reply":"2024-08-29T14:14:08.154593Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for column in df_train.columns:\n    # Calculate frequency counts for each value\n    value_counts = df_train[column].value_counts()\n    # Identify values with frequency lower than 20\n    low_frequency_values = value_counts[value_counts < 20].index\n    # Calculate the mode of the column\n    mode_value = df_train[column].mode()[0]\n    # Replace low-frequency values with the mode\n    df_train[column] = df_train[column].apply(lambda x: mode_value if x in low_frequency_values else x)\n\nfor column in df_test.columns:\n    # Calculate frequency counts for each value\n    value_counts = df_test[column].value_counts()\n    # Identify values with frequency lower than 20\n    low_frequency_values = value_counts[value_counts < 20].index\n    # Calculate the mode of the column\n    mode_value = df_test[column].mode()[0]\n    # Replace low-frequency values with the mode\n    df_test[column] = df_test[column].apply(lambda x: mode_value if x in low_frequency_values else x)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:14:08.157813Z","iopub.execute_input":"2024-08-29T14:14:08.158299Z","iopub.status.idle":"2024-08-29T14:17:22.590739Z","shell.execute_reply.started":"2024-08-29T14:14:08.158247Z","shell.execute_reply":"2024-08-29T14:17:22.589676Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"df_train = df_train.drop(['id'], axis = 1)\ndf_test = df_test.drop(['id'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:17:29.831153Z","iopub.execute_input":"2024-08-29T14:17:29.832139Z","iopub.status.idle":"2024-08-29T14:17:31.608291Z","shell.execute_reply.started":"2024-08-29T14:17:29.832084Z","shell.execute_reply":"2024-08-29T14:17:31.607112Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df_train.drop(columns = ['class'] , axis = 1)\ny = df_train['class']","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:17:31.610235Z","iopub.execute_input":"2024-08-29T14:17:31.610590Z","iopub.status.idle":"2024-08-29T14:17:32.330539Z","shell.execute_reply.started":"2024-08-29T14:17:31.610553Z","shell.execute_reply":"2024-08-29T14:17:32.329621Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\n\nclass FrequencyEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, columns=None):\n        self.columns = columns\n        self.frequency_maps = {}\n\n    def fit(self, X, y=None):\n        for column in self.columns:\n            frequency = X[column].value_counts()\n            self.frequency_maps[column] = frequency\n        return self\n\n    def transform(self, X):\n        X_transformed = X.copy()\n        for column in self.columns:\n            X_transformed[column + '_freq'] = X_transformed[column].map(self.frequency_maps[column])\n        return X_transformed","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:17:32.331767Z","iopub.execute_input":"2024-08-29T14:17:32.332106Z","iopub.status.idle":"2024-08-29T14:17:32.339595Z","shell.execute_reply.started":"2024-08-29T14:17:32.332070Z","shell.execute_reply":"2024-08-29T14:17:32.338411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define columns for frequency encoding\nfreq_cols = [column for column in df_train.select_dtypes(include='object').columns if column != 'class']\n\n# Define numerical columns\nnum_cols = [column for column in X.columns if column not in freq_cols]\n\n# Initialize FrequencyEncoder with the specified columns\nfreq_encoder = FrequencyEncoder(columns=freq_cols)\n\n# Fit the frequency encoder to the data\nfreq_encoder.fit(X)\n\n# Transform the data to include frequency encoded columns\nX_freq_encoded = freq_encoder.transform(X)\ndf_test_freq_encoded = freq_encoder.transform(df_test)\n\n# Define the preprocessing for numerical and categorical columns\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), num_cols),\n        ('freq', 'passthrough', [col + '_freq' for col in freq_cols])\n    ])\n\n# Fit and transform the training data\nX_processed = preprocessor.fit_transform(X_freq_encoded)\ndf_test_processed = preprocessor.transform(df_test_freq_encoded)\n\n# Convert processed arrays back to DataFrames\nX_processed = pd.DataFrame(X_processed, columns=preprocessor.get_feature_names_out())\ndf_test_processed = pd.DataFrame(df_test_processed, columns=preprocessor.get_feature_names_out())\n\n# Keep dataframe names consistent\nX = X_processed\ndf_test = df_test_processed","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:17:32.341548Z","iopub.execute_input":"2024-08-29T14:17:32.341920Z","iopub.status.idle":"2024-08-29T14:17:47.109330Z","shell.execute_reply.started":"2024-08-29T14:17:32.341882Z","shell.execute_reply":"2024-08-29T14:17:47.108148Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Deep Learning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=2)\n\nle = LabelEncoder()\n# Convert the target variable 'response' to numerical data\ny_train = le.fit_transform(y_train)\ny_val = le.transform(y_val)\ny_train\n\n# Define model\nmodel = Sequential([\n    Input(shape=(X_train.shape[1],)),\n    Dense(512, activation='linear'),\n    BatchNormalization(),\n    Dropout(0.36), \n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.3), \n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.24),  \n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.2),  \n    Dense(32, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.16),  \n    Dense(16, activation='relu'), \n    BatchNormalization(),\n    Dropout(0.12),  \n    Dense(8, activation='relu'), \n    BatchNormalization(),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile model\nlittle_adam = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(loss='binary_crossentropy',optimizer=little_adam, metrics=['accuracy'])\n\n# Callbacks for early stopping and learning rate reduction\nearly_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.15, patience=25, min_lr=1e-6)\n\n# Train model\nhistory = model.fit(X_train, y_train,\n                    epochs=50,\n                    batch_size=128,\n                    validation_data=(X_val, y_val),\n                    callbacks=[early_stopping, reduce_lr])\n\n\n\n# Plot training & validation loss values\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'])\n\n# Plot training & validation accuracy values\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:22:01.830113Z","iopub.execute_input":"2024-08-29T14:22:01.831212Z","iopub.status.idle":"2024-08-29T19:10:00.710382Z","shell.execute_reply.started":"2024-08-29T14:22:01.831163Z","shell.execute_reply":"2024-08-29T19:10:00.709116Z"},"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"test_predictions = (model.predict(df_test_processed) > 0.5).astype(int).flatten()\ndf_sub = pd.read_csv('/kaggle/input/playground-series-s4e8/sample_submission.csv')\ndf_sub['class'] = np.where(test_predictions == 1, 'p', 'e')\ndf_sub.to_csv('submission_nn.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T19:10:07.748536Z","iopub.execute_input":"2024-08-29T19:10:07.749590Z","iopub.status.idle":"2024-08-29T19:12:32.271257Z","shell.execute_reply.started":"2024-08-29T19:10:07.749544Z","shell.execute_reply":"2024-08-29T19:12:32.270227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}